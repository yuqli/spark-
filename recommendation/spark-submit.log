nohup: ignoring input
17/12/09 15:55:35 INFO spark.SparkContext: Running Spark version 1.6.0
17/12/09 15:55:37 INFO spark.SecurityManager: Changing view acls to: yl5090
17/12/09 15:55:37 INFO spark.SecurityManager: Changing modify acls to: yl5090
17/12/09 15:55:37 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(yl5090); users with modify permissions: Set(yl5090)
17/12/09 15:55:38 INFO util.Utils: Successfully started service 'sparkDriver' on port 36664.
17/12/09 15:55:38 INFO slf4j.Slf4jLogger: Slf4jLogger started
17/12/09 15:55:38 INFO Remoting: Starting remoting
17/12/09 15:55:39 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@10.0.255.253:43666]
17/12/09 15:55:39 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriverActorSystem@10.0.255.253:43666]
17/12/09 15:55:39 INFO util.Utils: Successfully started service 'sparkDriverActorSystem' on port 43666.
17/12/09 15:55:39 INFO spark.SparkEnv: Registering MapOutputTracker
17/12/09 15:55:39 INFO spark.SparkEnv: Registering BlockManagerMaster
17/12/09 15:55:39 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-7717c332-25b0-4ec0-a1c5-13385b3c5b9c
17/12/09 15:55:39 INFO storage.MemoryStore: MemoryStore started with capacity 530.3 MB
17/12/09 15:55:39 INFO spark.SparkEnv: Registering OutputCommitCoordinator
17/12/09 15:55:40 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
17/12/09 15:55:40 WARN util.Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
17/12/09 15:55:40 WARN util.Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
17/12/09 15:55:40 WARN util.Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
17/12/09 15:55:40 WARN util.Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
17/12/09 15:55:40 WARN util.Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.
17/12/09 15:55:40 WARN util.Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.
17/12/09 15:55:40 WARN util.Utils: Service 'SparkUI' could not bind on port 4047. Attempting port 4048.
17/12/09 15:55:40 WARN util.Utils: Service 'SparkUI' could not bind on port 4048. Attempting port 4049.
17/12/09 15:55:40 WARN util.Utils: Service 'SparkUI' could not bind on port 4049. Attempting port 4050.
17/12/09 15:55:40 WARN util.Utils: Service 'SparkUI' could not bind on port 4050. Attempting port 4051.
17/12/09 15:55:40 WARN util.Utils: Service 'SparkUI' could not bind on port 4051. Attempting port 4052.
17/12/09 15:55:40 WARN util.Utils: Service 'SparkUI' could not bind on port 4052. Attempting port 4053.
17/12/09 15:55:40 WARN util.Utils: Service 'SparkUI' could not bind on port 4053. Attempting port 4054.
17/12/09 15:55:40 WARN util.Utils: Service 'SparkUI' could not bind on port 4054. Attempting port 4055.
17/12/09 15:55:40 WARN util.Utils: Service 'SparkUI' could not bind on port 4055. Attempting port 4056.
17/12/09 15:55:40 WARN util.Utils: Service 'SparkUI' could not bind on port 4056. Attempting port 4057.
17/12/09 15:55:40 WARN util.Utils: Service 'SparkUI' could not bind on port 4057. Attempting port 4058.
17/12/09 15:55:40 WARN util.Utils: Service 'SparkUI' could not bind on port 4058. Attempting port 4059.
17/12/09 15:55:40 WARN util.Utils: Service 'SparkUI' could not bind on port 4059. Attempting port 4060.
17/12/09 15:55:40 WARN util.Utils: Service 'SparkUI' could not bind on port 4060. Attempting port 4061.
17/12/09 15:55:40 WARN util.Utils: Service 'SparkUI' could not bind on port 4061. Attempting port 4062.
17/12/09 15:55:40 INFO util.Utils: Successfully started service 'SparkUI' on port 4062.
17/12/09 15:55:40 INFO ui.SparkUI: Started SparkUI at http://10.0.255.253:4062
17/12/09 15:55:41 INFO yarn.Client: Requesting a new application from cluster with 43 NodeManagers
17/12/09 15:55:41 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (65536 MB per container)
17/12/09 15:55:41 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
17/12/09 15:55:41 INFO yarn.Client: Setting up container launch context for our AM
17/12/09 15:55:41 INFO yarn.Client: Setting up the launch environment for our AM container
17/12/09 15:55:41 INFO yarn.Client: Preparing resources for our AM container
17/12/09 15:55:43 INFO yarn.Client: Uploading resource file:/tmp/spark-9a42fdd3-5459-47c1-95bb-36ee6032a0d9/__spark_conf__5109410983010319454.zip -> hdfs://dumbo/user/yl5090/.sparkStaging/application_1512409949844_1822/__spark_conf__5109410983010319454.zip
17/12/09 15:55:44 INFO spark.SecurityManager: Changing view acls to: yl5090
17/12/09 15:55:44 INFO spark.SecurityManager: Changing modify acls to: yl5090
17/12/09 15:55:44 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(yl5090); users with modify permissions: Set(yl5090)
17/12/09 15:55:44 INFO yarn.Client: Submitting application 1822 to ResourceManager
17/12/09 15:55:44 INFO impl.YarnClientImpl: Submitted application application_1512409949844_1822
17/12/09 15:55:45 INFO yarn.Client: Application report for application_1512409949844_1822 (state: ACCEPTED)
17/12/09 15:55:45 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: root.users.yl5090
	 start time: 1512852944485
	 final status: UNDEFINED
	 tracking URL: http://babar.es.its.nyu.edu:8088/proxy/application_1512409949844_1822/
	 user: yl5090
17/12/09 15:55:46 INFO yarn.Client: Application report for application_1512409949844_1822 (state: ACCEPTED)
17/12/09 15:55:47 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(null)
17/12/09 15:55:47 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> babar.es.its.nyu.edu,compute-1-8.local, PROXY_URI_BASES -> http://babar.es.its.nyu.edu:8088/proxy/application_1512409949844_1822,http://compute-1-8.local:8088/proxy/application_1512409949844_1822), /proxy/application_1512409949844_1822
17/12/09 15:55:47 INFO ui.JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
17/12/09 15:55:47 INFO yarn.Client: Application report for application_1512409949844_1822 (state: RUNNING)
17/12/09 15:55:47 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 10.0.255.252
	 ApplicationMaster RPC port: 0
	 queue: root.users.yl5090
	 start time: 1512852944485
	 final status: UNDEFINED
	 tracking URL: http://babar.es.its.nyu.edu:8088/proxy/application_1512409949844_1822/
	 user: yl5090
17/12/09 15:55:47 INFO cluster.YarnClientSchedulerBackend: Application application_1512409949844_1822 has started running.
17/12/09 15:55:47 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40982.
17/12/09 15:55:47 INFO netty.NettyBlockTransferService: Server created on 40982
17/12/09 15:55:47 INFO storage.BlockManager: external shuffle service port = 7337
17/12/09 15:55:47 INFO storage.BlockManagerMaster: Trying to register BlockManager
17/12/09 15:55:47 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.0.255.253:40982 with 530.3 MB RAM, BlockManagerId(driver, 10.0.255.253, 40982)
17/12/09 15:55:47 INFO storage.BlockManagerMaster: Registered BlockManager
17/12/09 15:55:48 INFO scheduler.EventLoggingListener: Logging events to hdfs://dumbo/user/spark/applicationHistory/application_1512409949844_1822
17/12/09 15:55:48 INFO spark.SparkContext: Registered listener com.cloudera.spark.lineage.ClouderaNavigatorListener
17/12/09 15:55:48 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
17/12/09 15:55:50 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 217.9 KB, free 530.1 MB)
17/12/09 15:55:50 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 26.0 KB, free 530.0 MB)
17/12/09 15:55:50 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.255.253:40982 (size: 26.0 KB, free: 530.3 MB)
17/12/09 15:55:50 INFO spark.SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2
17/12/09 15:55:50 INFO mapred.FileInputFormat: Total input paths to process : 1
17/12/09 15:55:51 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
17/12/09 15:55:51 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
17/12/09 15:55:51 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
17/12/09 15:55:51 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
17/12/09 15:55:51 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
17/12/09 15:55:51 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
17/12/09 15:55:51 INFO spark.SparkContext: Starting job: saveAsTextFile at NativeMethodAccessorImpl.java:-2
17/12/09 15:55:51 INFO scheduler.DAGScheduler: Registering RDD 5 (combineByKey at /home/yl5090/recommendation2.py:48)
17/12/09 15:55:51 INFO scheduler.DAGScheduler: Got job 0 (saveAsTextFile at NativeMethodAccessorImpl.java:-2) with 4 output partitions
17/12/09 15:55:51 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (saveAsTextFile at NativeMethodAccessorImpl.java:-2)
17/12/09 15:55:51 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
17/12/09 15:55:51 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 0)
17/12/09 15:55:51 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[5] at combineByKey at /home/yl5090/recommendation2.py:48), which has no missing parents
17/12/09 15:55:51 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.5 KB, free 530.0 MB)
17/12/09 15:55:51 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KB, free 530.0 MB)
17/12/09 15:55:51 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.255.253:40982 (size: 6.2 KB, free: 530.2 MB)
17/12/09 15:55:51 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1004
17/12/09 15:55:51 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 0 (PairwiseRDD[5] at combineByKey at /home/yl5090/recommendation2.py:48) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
17/12/09 15:55:51 INFO cluster.YarnScheduler: Adding task set 0.0 with 4 tasks
17/12/09 15:55:52 INFO spark.ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)
17/12/09 15:55:53 INFO spark.ExecutorAllocationManager: Requesting 2 new executors because tasks are backlogged (new desired total will be 3)
17/12/09 15:55:54 INFO spark.ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 4)
17/12/09 15:55:55 INFO cluster.YarnClientSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (compute-1-2.local:59800) with ID 1
17/12/09 15:55:55 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, compute-1-2.local, executor 1, partition 0, NODE_LOCAL, 2343 bytes)
17/12/09 15:55:55 INFO storage.BlockManagerMasterEndpoint: Registering block manager compute-1-2.local:33375 with 530.3 MB RAM, BlockManagerId(1, compute-1-2.local, 33375)
17/12/09 15:55:55 INFO spark.ExecutorAllocationManager: New executor 1 has registered (new total is 1)
17/12/09 15:55:55 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on compute-1-2.local:33375 (size: 6.2 KB, free: 530.3 MB)
17/12/09 15:55:55 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on compute-1-2.local:33375 (size: 26.0 KB, free: 530.2 MB)
17/12/09 15:55:56 INFO cluster.YarnClientSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (compute-1-15.local:57768) with ID 2
17/12/09 15:55:56 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, compute-1-15.local, executor 2, partition 1, NODE_LOCAL, 2502 bytes)
17/12/09 15:55:56 INFO spark.ExecutorAllocationManager: New executor 2 has registered (new total is 2)
17/12/09 15:55:56 INFO cluster.YarnClientSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (compute-1-10.local:34722) with ID 3
17/12/09 15:55:56 INFO spark.ExecutorAllocationManager: New executor 3 has registered (new total is 3)
17/12/09 15:55:56 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, compute-1-10.local, executor 3, partition 2, NODE_LOCAL, 2502 bytes)
17/12/09 15:55:56 INFO storage.BlockManagerMasterEndpoint: Registering block manager compute-1-15.local:36437 with 530.3 MB RAM, BlockManagerId(2, compute-1-15.local, 36437)
17/12/09 15:55:56 INFO storage.BlockManagerMasterEndpoint: Registering block manager compute-1-10.local:53876 with 530.3 MB RAM, BlockManagerId(3, compute-1-10.local, 53876)
17/12/09 15:55:56 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on compute-1-15.local:36437 (size: 6.2 KB, free: 530.3 MB)
17/12/09 15:55:56 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on compute-1-10.local:53876 (size: 6.2 KB, free: 530.3 MB)
17/12/09 15:55:56 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on compute-1-15.local:36437 (size: 26.0 KB, free: 530.2 MB)
17/12/09 15:55:56 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on compute-1-10.local:53876 (size: 26.0 KB, free: 530.2 MB)
17/12/09 15:55:57 INFO cluster.YarnClientSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (compute-1-2.local:59808) with ID 4
17/12/09 15:55:57 INFO spark.ExecutorAllocationManager: New executor 4 has registered (new total is 4)
17/12/09 15:55:57 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, compute-1-2.local, executor 4, partition 3, NODE_LOCAL, 2343 bytes)
17/12/09 15:55:57 INFO storage.BlockManagerMasterEndpoint: Registering block manager compute-1-2.local:44873 with 530.3 MB RAM, BlockManagerId(4, compute-1-2.local, 44873)
17/12/09 15:55:57 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on compute-1-2.local:44873 (size: 6.2 KB, free: 530.3 MB)
17/12/09 15:55:57 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on compute-1-2.local:44873 (size: 26.0 KB, free: 530.2 MB)
17/12/09 15:55:57 INFO storage.BlockManagerInfo: Added rdd_2_0 in memory on compute-1-2.local:33375 (size: 3.2 MB, free: 527.0 MB)
17/12/09 15:55:58 INFO storage.BlockManagerInfo: Added rdd_2_0 in memory on compute-1-15.local:36437 (size: 3.2 MB, free: 527.0 MB)
17/12/09 15:55:58 INFO storage.BlockManagerInfo: Added rdd_2_1 in memory on compute-1-10.local:53876 (size: 2.9 MB, free: 527.4 MB)
17/12/09 15:55:58 INFO storage.BlockManagerInfo: Added rdd_2_1 in memory on compute-1-15.local:36437 (size: 2.9 MB, free: 524.1 MB)
17/12/09 15:55:59 INFO storage.BlockManagerInfo: Added rdd_2_1 in memory on compute-1-2.local:44873 (size: 2.9 MB, free: 527.4 MB)
17/12/09 16:26:16 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1820944 ms on compute-1-2.local (executor 1) (1/4)
17/12/09 16:49:02 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 3185959 ms on compute-1-10.local (executor 3) (2/4)
17/12/09 16:50:16 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 3260143 ms on compute-1-15.local (executor 2) (3/4)
17/12/09 17:25:47 INFO scheduler.DAGScheduler: ShuffleMapStage 0 (combineByKey at /home/yl5090/recommendation2.py:48) finished in 5395.306 s
17/12/09 17:25:47 INFO scheduler.DAGScheduler: looking for newly runnable stages
17/12/09 17:25:47 INFO scheduler.DAGScheduler: running: Set()
17/12/09 17:25:47 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 1)
17/12/09 17:25:47 INFO scheduler.DAGScheduler: failed: Set()
17/12/09 17:25:47 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[10] at saveAsTextFile at NativeMethodAccessorImpl.java:-2), which has no missing parents
17/12/09 17:25:47 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 5390294 ms on compute-1-2.local (executor 4) (4/4)
17/12/09 17:25:47 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/12/09 17:25:47 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 85.5 KB, free 529.9 MB)
17/12/09 17:25:47 INFO storage.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.1 KB, free 529.9 MB)
17/12/09 17:25:47 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.0.255.253:40982 (size: 32.1 KB, free: 530.2 MB)
17/12/09 17:25:47 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1004
17/12/09 17:25:47 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from ResultStage 1 (MapPartitionsRDD[10] at saveAsTextFile at NativeMethodAccessorImpl.java:-2) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
17/12/09 17:25:47 INFO cluster.YarnScheduler: Adding task set 1.0 with 4 tasks
17/12/09 17:25:47 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 4, compute-1-10.local, executor 3, partition 0, NODE_LOCAL, 1894 bytes)
17/12/09 17:25:47 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 1.0 (TID 5, compute-1-2.local, executor 1, partition 1, NODE_LOCAL, 1894 bytes)
17/12/09 17:25:47 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 1.0 (TID 6, compute-1-2.local, executor 4, partition 2, NODE_LOCAL, 1894 bytes)
17/12/09 17:25:47 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 1.0 (TID 7, compute-1-15.local, executor 2, partition 3, NODE_LOCAL, 1894 bytes)
17/12/09 17:25:47 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on compute-1-2.local:33375 (size: 32.1 KB, free: 527.0 MB)
17/12/09 17:25:47 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on compute-1-10.local:53876 (size: 32.1 KB, free: 527.3 MB)
17/12/09 17:25:47 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on compute-1-15.local:36437 (size: 32.1 KB, free: 524.1 MB)
17/12/09 17:25:47 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on compute-1-2.local:44873 (size: 32.1 KB, free: 527.3 MB)
17/12/09 17:25:47 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to compute-1-2.local:59800
17/12/09 17:25:47 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to compute-1-10.local:34722
17/12/09 17:25:47 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 191 bytes
17/12/09 17:25:47 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to compute-1-15.local:57768
17/12/09 17:25:47 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to compute-1-2.local:59808
17/12/09 17:25:49 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on 10.0.255.253:40982 in memory (size: 6.2 KB, free: 530.2 MB)
17/12/09 17:25:49 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on compute-1-10.local:53876 in memory (size: 6.2 KB, free: 527.3 MB)
17/12/09 17:25:49 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on compute-1-2.local:44873 in memory (size: 6.2 KB, free: 527.3 MB)
17/12/09 17:25:49 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on compute-1-2.local:33375 in memory (size: 6.2 KB, free: 527.0 MB)
17/12/09 17:25:49 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on compute-1-15.local:36437 in memory (size: 6.2 KB, free: 524.1 MB)
17/12/09 17:25:50 INFO cluster.YarnClientSchedulerBackend: Disabling executor 3.
17/12/09 17:25:50 INFO scheduler.DAGScheduler: Executor lost: 3 (epoch 1)
17/12/09 17:25:50 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 3 from BlockManagerMaster.
17/12/09 17:25:50 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(3, compute-1-10.local, 53876)
17/12/09 17:25:50 INFO storage.BlockManagerMaster: Removed 3 successfully in removeExecutor
17/12/09 17:25:50 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Container killed by YARN for exceeding memory limits. 2.1 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.
17/12/09 17:25:50 ERROR cluster.YarnScheduler: Lost executor 3 on compute-1-10.local: Container killed by YARN for exceeding memory limits. 2.1 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.
17/12/09 17:25:50 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 1.0 (TID 4, compute-1-10.local, executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. 2.1 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.
17/12/09 17:25:50 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 3 from BlockManagerMaster.
17/12/09 17:25:50 INFO storage.BlockManagerMaster: Removal of executor 3 requested
17/12/09 17:25:50 INFO cluster.YarnClientSchedulerBackend: Asked to remove non-existent executor 3
17/12/09 17:25:50 INFO spark.ExecutorAllocationManager: Existing executor 3 has been removed (new total is 3)
17/12/09 17:25:50 INFO cluster.YarnClientSchedulerBackend: Disabling executor 4.
17/12/09 17:25:50 INFO scheduler.DAGScheduler: Executor lost: 4 (epoch 1)
17/12/09 17:25:50 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 4 from BlockManagerMaster.
17/12/09 17:25:50 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(4, compute-1-2.local, 44873)
17/12/09 17:25:50 INFO storage.BlockManagerMaster: Removed 4 successfully in removeExecutor
17/12/09 17:25:50 INFO cluster.YarnClientSchedulerBackend: Disabling executor 2.
17/12/09 17:25:50 INFO scheduler.DAGScheduler: Executor lost: 2 (epoch 1)
17/12/09 17:25:50 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.
17/12/09 17:25:50 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(2, compute-1-15.local, 36437)
17/12/09 17:25:50 INFO storage.BlockManagerMaster: Removed 2 successfully in removeExecutor
17/12/09 17:25:51 ERROR cluster.YarnScheduler: Lost executor 2 on compute-1-15.local: Container marked as failed: container_e92_1512409949844_1822_01_000003 on host: compute-1-15.local. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal

17/12/09 17:25:51 WARN scheduler.TaskSetManager: Lost task 3.0 in stage 1.0 (TID 7, compute-1-15.local, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_e92_1512409949844_1822_01_000003 on host: compute-1-15.local. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal

17/12/09 17:25:51 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Container marked as failed: container_e92_1512409949844_1822_01_000003 on host: compute-1-15.local. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal

17/12/09 17:25:51 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Container marked as failed: container_e92_1512409949844_1822_01_000005 on host: compute-1-2.local. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal

17/12/09 17:25:51 ERROR cluster.YarnScheduler: Lost executor 4 on compute-1-2.local: Container marked as failed: container_e92_1512409949844_1822_01_000005 on host: compute-1-2.local. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal

17/12/09 17:25:51 WARN scheduler.TaskSetManager: Lost task 2.0 in stage 1.0 (TID 6, compute-1-2.local, executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container marked as failed: container_e92_1512409949844_1822_01_000005 on host: compute-1-2.local. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal

17/12/09 17:25:51 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Container killed by YARN for exceeding memory limits. 1.9 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.
17/12/09 17:25:51 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.
17/12/09 17:25:51 INFO storage.BlockManagerMaster: Removal of executor 2 requested
17/12/09 17:25:51 INFO cluster.YarnClientSchedulerBackend: Asked to remove non-existent executor 2
17/12/09 17:25:51 INFO storage.BlockManagerMaster: Removal of executor 4 requested
17/12/09 17:25:51 INFO cluster.YarnClientSchedulerBackend: Asked to remove non-existent executor 4
17/12/09 17:25:51 ERROR cluster.YarnScheduler: Lost executor 1 on compute-1-2.local: Container killed by YARN for exceeding memory limits. 1.9 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.
17/12/09 17:25:51 INFO spark.ExecutorAllocationManager: Existing executor 2 has been removed (new total is 2)
17/12/09 17:25:51 WARN scheduler.TaskSetManager: Lost task 1.0 in stage 1.0 (TID 5, compute-1-2.local, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. 1.9 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.
17/12/09 17:25:51 INFO scheduler.DAGScheduler: Executor lost: 1 (epoch 1)
17/12/09 17:25:51 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 4 from BlockManagerMaster.
17/12/09 17:25:51 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.
17/12/09 17:25:51 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(1, compute-1-2.local, 33375)
17/12/09 17:25:51 INFO storage.BlockManagerMaster: Removed 1 successfully in removeExecutor
17/12/09 17:25:51 INFO spark.ExecutorAllocationManager: Existing executor 4 has been removed (new total is 1)
17/12/09 17:25:51 INFO spark.ExecutorAllocationManager: Existing executor 1 has been removed (new total is 0)
17/12/09 17:25:51 WARN server.TransportChannelHandler: Exception in connection from compute-1-2.local/10.0.255.238:59800
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:313)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:881)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:242)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:119)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	at java.lang.Thread.run(Thread.java:745)
17/12/09 17:25:51 INFO cluster.YarnClientSchedulerBackend: Disabling executor 1.
17/12/09 17:25:51 ERROR cluster.YarnScheduler: Lost an executor 1 (already removed): Pending loss reason.
17/12/09 17:25:51 INFO storage.BlockManagerMaster: Removal of executor 1 requested
17/12/09 17:25:51 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.
17/12/09 17:25:51 INFO cluster.YarnClientSchedulerBackend: Asked to remove non-existent executor 1
17/12/09 17:25:51 INFO spark.ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)
17/12/09 17:25:52 INFO spark.ExecutorAllocationManager: Requesting 2 new executors because tasks are backlogged (new desired total will be 4)
17/12/09 17:25:53 INFO cluster.YarnClientSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (compute-1-15.local:37671) with ID 6
17/12/09 17:25:53 INFO scheduler.TaskSetManager: Starting task 1.1 in stage 1.0 (TID 8, compute-1-15.local, executor 6, partition 1, NODE_LOCAL, 1894 bytes)
17/12/09 17:25:53 INFO spark.ExecutorAllocationManager: New executor 6 has registered (new total is 1)
17/12/09 17:25:53 INFO storage.BlockManagerMasterEndpoint: Registering block manager compute-1-15.local:36591 with 530.3 MB RAM, BlockManagerId(6, compute-1-15.local, 36591)
17/12/09 17:25:53 INFO cluster.YarnClientSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (compute-1-2.local:39711) with ID 5
17/12/09 17:25:53 INFO scheduler.TaskSetManager: Starting task 2.1 in stage 1.0 (TID 9, compute-1-2.local, executor 5, partition 2, NODE_LOCAL, 1894 bytes)
17/12/09 17:25:53 INFO spark.ExecutorAllocationManager: New executor 5 has registered (new total is 2)
17/12/09 17:25:53 INFO storage.BlockManagerMasterEndpoint: Registering block manager compute-1-2.local:55142 with 530.3 MB RAM, BlockManagerId(5, compute-1-2.local, 55142)
17/12/09 17:25:54 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on compute-1-15.local:36591 (size: 32.1 KB, free: 530.2 MB)
17/12/09 17:25:54 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on compute-1-2.local:55142 (size: 32.1 KB, free: 530.2 MB)
17/12/09 17:25:54 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to compute-1-15.local:37671
17/12/09 17:25:54 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to compute-1-2.local:39711
17/12/09 17:25:54 INFO cluster.YarnClientSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (compute-1-10.local:42870) with ID 7
17/12/09 17:25:54 INFO scheduler.TaskSetManager: Starting task 3.1 in stage 1.0 (TID 10, compute-1-10.local, executor 7, partition 3, NODE_LOCAL, 1894 bytes)
17/12/09 17:25:54 INFO spark.ExecutorAllocationManager: New executor 7 has registered (new total is 3)
17/12/09 17:25:54 INFO storage.BlockManagerMasterEndpoint: Registering block manager compute-1-10.local:59597 with 530.3 MB RAM, BlockManagerId(7, compute-1-10.local, 59597)
17/12/09 17:25:55 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on compute-1-10.local:59597 (size: 32.1 KB, free: 530.2 MB)
17/12/09 17:25:55 INFO cluster.YarnClientSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (compute-1-2.local:39717) with ID 8
17/12/09 17:25:55 INFO scheduler.TaskSetManager: Starting task 0.1 in stage 1.0 (TID 11, compute-1-2.local, executor 8, partition 0, NODE_LOCAL, 1894 bytes)
17/12/09 17:25:55 INFO spark.ExecutorAllocationManager: New executor 8 has registered (new total is 4)
17/12/09 17:25:55 INFO storage.BlockManagerMasterEndpoint: Registering block manager compute-1-2.local:53156 with 530.3 MB RAM, BlockManagerId(8, compute-1-2.local, 53156)
17/12/09 17:25:55 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on compute-1-2.local:53156 (size: 32.1 KB, free: 530.2 MB)
17/12/09 17:25:55 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to compute-1-10.local:42870
17/12/09 17:25:55 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to compute-1-2.local:39717
17/12/09 17:25:56 WARN scheduler.TaskSetManager: Lost task 2.1 in stage 1.0 (TID 9, compute-1-2.local, executor 5): FetchFailed(BlockManagerId(2, compute-1-15.local, 7337), shuffleId=0, mapId=1, reduceId=2, message=
org.apache.spark.shuffle.FetchFailedException: Direct buffer memory
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:383)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:361)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:55)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:452)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:280)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1819)
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:239)
Caused by: java.lang.OutOfMemoryError: Direct buffer memory
	at java.nio.Bits.reserveMemory(Bits.java:658)
	at java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:123)
	at java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:306)
	at io.netty.buffer.PoolArena$DirectArena.newChunk(PoolArena.java:645)
	at io.netty.buffer.PoolArena.allocateNormal(PoolArena.java:228)
	at io.netty.buffer.PoolArena.allocate(PoolArena.java:212)
	at io.netty.buffer.PoolArena.allocate(PoolArena.java:132)
	at io.netty.buffer.PooledByteBufAllocator.newDirectBuffer(PooledByteBufAllocator.java:271)
	at io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:155)
	at io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:146)
	at io.netty.buffer.AbstractByteBufAllocator.ioBuffer(AbstractByteBufAllocator.java:107)
	at io.netty.channel.AdaptiveRecvByteBufAllocator$HandleImpl.allocate(AdaptiveRecvByteBufAllocator.java:104)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:117)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	at java.lang.Thread.run(Thread.java:745)

)
17/12/09 17:25:56 INFO scheduler.TaskSetManager: Task 2.1 in stage 1.0 (TID 9) failed, but another instance of the task has already succeeded, so not re-queuing the task to be re-executed.
17/12/09 17:25:56 INFO scheduler.DAGScheduler: Marking ResultStage 1 (saveAsTextFile at NativeMethodAccessorImpl.java:-2) as failed due to a fetch failure from ShuffleMapStage 0 (combineByKey at /home/yl5090/recommendation2.py:48)
17/12/09 17:25:56 INFO scheduler.DAGScheduler: ResultStage 1 (saveAsTextFile at NativeMethodAccessorImpl.java:-2) failed in 8.592 s due to org.apache.spark.shuffle.FetchFailedException: Direct buffer memory
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:383)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:361)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:55)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:452)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:280)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1819)
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:239)
Caused by: java.lang.OutOfMemoryError: Direct buffer memory
	at java.nio.Bits.reserveMemory(Bits.java:658)
	at java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:123)
	at java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:306)
	at io.netty.buffer.PoolArena$DirectArena.newChunk(PoolArena.java:645)
	at io.netty.buffer.PoolArena.allocateNormal(PoolArena.java:228)
	at io.netty.buffer.PoolArena.allocate(PoolArena.java:212)
	at io.netty.buffer.PoolArena.allocate(PoolArena.java:132)
	at io.netty.buffer.PooledByteBufAllocator.newDirectBuffer(PooledByteBufAllocator.java:271)
	at io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:155)
	at io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:146)
	at io.netty.buffer.AbstractByteBufAllocator.ioBuffer(AbstractByteBufAllocator.java:107)
	at io.netty.channel.AdaptiveRecvByteBufAllocator$HandleImpl.allocate(AdaptiveRecvByteBufAllocator.java:104)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:117)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	at java.lang.Thread.run(Thread.java:745)

17/12/09 17:25:56 INFO scheduler.DAGScheduler: Resubmitting ShuffleMapStage 0 (combineByKey at /home/yl5090/recommendation2.py:48) and ResultStage 1 (saveAsTextFile at NativeMethodAccessorImpl.java:-2) due to fetch failure
17/12/09 17:25:56 WARN spark.ExecutorAllocationManager: No stages are running, but numRunningTasks != 0
17/12/09 17:25:56 INFO scheduler.DAGScheduler: Resubmitting failed stages
17/12/09 17:25:56 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[5] at combineByKey at /home/yl5090/recommendation2.py:48), which has no missing parents
17/12/09 17:25:56 INFO storage.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 10.5 KB, free 529.9 MB)
17/12/09 17:25:56 INFO storage.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.2 KB, free 529.9 MB)
17/12/09 17:25:56 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.0.255.253:40982 (size: 6.2 KB, free: 530.2 MB)
17/12/09 17:25:56 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1004
17/12/09 17:25:56 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (PairwiseRDD[5] at combineByKey at /home/yl5090/recommendation2.py:48) (first 15 tasks are for partitions Vector(1))
17/12/09 17:25:56 INFO cluster.YarnScheduler: Adding task set 0.1 with 1 tasks
17/12/09 17:25:56 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.1 (TID 12, compute-1-2.local, executor 5, partition 1, NODE_LOCAL, 2502 bytes)
17/12/09 17:25:56 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on compute-1-2.local:55142 (size: 6.2 KB, free: 530.2 MB)
17/12/09 17:25:56 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on compute-1-2.local:55142 (size: 26.0 KB, free: 530.2 MB)
17/12/09 17:25:57 WARN scheduler.TaskSetManager: Lost task 3.1 in stage 1.0 (TID 10, compute-1-10.local, executor 7): FetchFailed(BlockManagerId(2, compute-1-15.local, 7337), shuffleId=0, mapId=1, reduceId=3, message=
org.apache.spark.shuffle.FetchFailedException: Direct buffer memory
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:383)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:361)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:55)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:452)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:280)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1819)
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:239)
Caused by: java.lang.OutOfMemoryError: Direct buffer memory
	at java.nio.Bits.reserveMemory(Bits.java:658)
	at java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:123)
	at java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:306)
	at io.netty.buffer.PoolArena$DirectArena.newChunk(PoolArena.java:645)
	at io.netty.buffer.PoolArena.allocateNormal(PoolArena.java:228)
	at io.netty.buffer.PoolArena.allocate(PoolArena.java:212)
	at io.netty.buffer.PoolArena.allocate(PoolArena.java:132)
	at io.netty.buffer.PooledByteBufAllocator.newDirectBuffer(PooledByteBufAllocator.java:271)
	at io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:155)
	at io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:146)
	at io.netty.buffer.AbstractByteBufAllocator.ioBuffer(AbstractByteBufAllocator.java:107)
	at io.netty.channel.AdaptiveRecvByteBufAllocator$HandleImpl.allocate(AdaptiveRecvByteBufAllocator.java:104)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:117)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	at java.lang.Thread.run(Thread.java:745)

)
17/12/09 17:25:57 INFO scheduler.TaskSetManager: Task 3.1 in stage 1.0 (TID 10) failed, but another instance of the task has already succeeded, so not re-queuing the task to be re-executed.
17/12/09 17:25:57 INFO scheduler.DAGScheduler: Resubmitting ShuffleMapStage 0 (combineByKey at /home/yl5090/recommendation2.py:48) and ResultStage 1 (saveAsTextFile at NativeMethodAccessorImpl.java:-2) due to fetch failure
17/12/09 17:25:57 WARN scheduler.TaskSetManager: Lost task 0.1 in stage 1.0 (TID 11, compute-1-2.local, executor 8): FetchFailed(BlockManagerId(2, compute-1-15.local, 7337), shuffleId=0, mapId=1, reduceId=0, message=
org.apache.spark.shuffle.FetchFailedException: Direct buffer memory
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:383)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:361)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:55)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:452)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:280)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1819)
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:239)
Caused by: java.lang.OutOfMemoryError: Direct buffer memory
	at java.nio.Bits.reserveMemory(Bits.java:658)
	at java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:123)
	at java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:306)
	at io.netty.buffer.PoolArena$DirectArena.newChunk(PoolArena.java:645)
	at io.netty.buffer.PoolArena.allocateNormal(PoolArena.java:228)
	at io.netty.buffer.PoolArena.allocate(PoolArena.java:212)
	at io.netty.buffer.PoolArena.allocate(PoolArena.java:132)
	at io.netty.buffer.PooledByteBufAllocator.newDirectBuffer(PooledByteBufAllocator.java:271)
	at io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:155)
	at io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:146)
	at io.netty.buffer.AbstractByteBufAllocator.ioBuffer(AbstractByteBufAllocator.java:107)
	at io.netty.channel.AdaptiveRecvByteBufAllocator$HandleImpl.allocate(AdaptiveRecvByteBufAllocator.java:104)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:117)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	at java.lang.Thread.run(Thread.java:745)

)
17/12/09 17:25:57 INFO scheduler.TaskSetManager: Task 0.1 in stage 1.0 (TID 11) failed, but another instance of the task has already succeeded, so not re-queuing the task to be re-executed.
17/12/09 17:25:57 INFO scheduler.DAGScheduler: Resubmitting failed stages
17/12/09 17:25:57 INFO storage.BlockManagerInfo: Added rdd_2_0 in memory on compute-1-2.local:55142 (size: 3.2 MB, free: 527.0 MB)
17/12/09 17:25:58 INFO storage.BlockManagerInfo: Added rdd_2_1 in memory on compute-1-2.local:55142 (size: 2.9 MB, free: 524.1 MB)
17/12/09 17:26:00 INFO cluster.YarnClientSchedulerBackend: Disabling executor 6.
17/12/09 17:26:00 INFO scheduler.DAGScheduler: Executor lost: 6 (epoch 4)
17/12/09 17:26:00 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 6 from BlockManagerMaster.
17/12/09 17:26:00 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(6, compute-1-15.local, 36591)
17/12/09 17:26:00 INFO storage.BlockManagerMaster: Removed 6 successfully in removeExecutor
17/12/09 17:26:00 ERROR cluster.YarnScheduler: Lost executor 6 on compute-1-15.local: Container killed by YARN for exceeding memory limits. 3.9 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.
17/12/09 17:26:00 WARN scheduler.TaskSetManager: Lost task 1.1 in stage 1.0 (TID 8, compute-1-15.local, executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. 3.9 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.
17/12/09 17:26:00 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/12/09 17:26:00 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Container killed by YARN for exceeding memory limits. 3.9 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.
17/12/09 17:26:00 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 6 from BlockManagerMaster.
17/12/09 17:26:00 INFO storage.BlockManagerMaster: Removal of executor 6 requested
17/12/09 17:26:00 INFO cluster.YarnClientSchedulerBackend: Asked to remove non-existent executor 6
17/12/09 17:26:01 INFO spark.ExecutorAllocationManager: Existing executor 6 has been removed (new total is 3)
17/12/09 17:26:57 INFO cluster.YarnClientSchedulerBackend: Requesting to kill executor(s) 7
17/12/09 17:26:57 INFO spark.ExecutorAllocationManager: Removing executor 7 because it has been idle for 60 seconds (new desired total will be 2)
17/12/09 17:26:57 INFO cluster.YarnClientSchedulerBackend: Requesting to kill executor(s) 8
17/12/09 17:26:57 INFO spark.ExecutorAllocationManager: Removing executor 8 because it has been idle for 60 seconds (new desired total will be 1)
17/12/09 17:26:58 INFO cluster.YarnClientSchedulerBackend: Disabling executor 7.
17/12/09 17:26:58 INFO scheduler.DAGScheduler: Executor lost: 7 (epoch 4)
17/12/09 17:26:58 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 7 from BlockManagerMaster.
17/12/09 17:26:58 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(7, compute-1-10.local, 59597)
17/12/09 17:26:58 INFO storage.BlockManagerMaster: Removed 7 successfully in removeExecutor
17/12/09 17:26:58 INFO cluster.YarnScheduler: Executor 7 on compute-1-10.local killed by driver.
17/12/09 17:26:58 INFO spark.ExecutorAllocationManager: Existing executor 7 has been removed (new total is 2)
17/12/09 17:26:59 INFO cluster.YarnClientSchedulerBackend: Disabling executor 8.
17/12/09 17:26:59 INFO scheduler.DAGScheduler: Executor lost: 8 (epoch 4)
17/12/09 17:26:59 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 8 from BlockManagerMaster.
17/12/09 17:26:59 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(8, compute-1-2.local, 53156)
17/12/09 17:26:59 INFO storage.BlockManagerMaster: Removed 8 successfully in removeExecutor
17/12/09 17:26:59 INFO cluster.YarnScheduler: Executor 8 on compute-1-2.local killed by driver.
17/12/09 17:26:59 INFO spark.ExecutorAllocationManager: Existing executor 8 has been removed (new total is 1)
17/12/09 18:20:06 INFO scheduler.DAGScheduler: ShuffleMapStage 0 (combineByKey at /home/yl5090/recommendation2.py:48) finished in 3250.295 s
17/12/09 18:20:06 INFO scheduler.DAGScheduler: looking for newly runnable stages
17/12/09 18:20:06 INFO scheduler.DAGScheduler: running: Set()
17/12/09 18:20:06 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 1)
17/12/09 18:20:06 INFO scheduler.DAGScheduler: failed: Set()
17/12/09 18:20:06 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[10] at saveAsTextFile at NativeMethodAccessorImpl.java:-2), which has no missing parents
17/12/09 18:20:06 WARN spark.ExecutorAllocationManager: No stages are running, but numRunningTasks != 0
17/12/09 18:20:06 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.1 (TID 12) in 3250306 ms on compute-1-2.local (executor 5) (1/1)
17/12/09 18:20:06 INFO cluster.YarnScheduler: Removed TaskSet 0.1, whose tasks have all completed, from pool 
17/12/09 18:20:06 INFO storage.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 85.5 KB, free 529.8 MB)
17/12/09 18:20:06 INFO storage.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 32.1 KB, free 529.8 MB)
17/12/09 18:20:06 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.0.255.253:40982 (size: 32.1 KB, free: 530.2 MB)
17/12/09 18:20:06 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1004
17/12/09 18:20:06 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from ResultStage 1 (MapPartitionsRDD[10] at saveAsTextFile at NativeMethodAccessorImpl.java:-2) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
17/12/09 18:20:06 INFO cluster.YarnScheduler: Adding task set 1.1 with 4 tasks
17/12/09 18:20:06 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.1 (TID 13, compute-1-2.local, executor 5, partition 0, NODE_LOCAL, 1894 bytes)
17/12/09 18:20:06 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on compute-1-2.local:55142 (size: 32.1 KB, free: 524.1 MB)
17/12/09 18:20:06 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to compute-1-2.local:39711
17/12/09 18:20:06 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 187 bytes
17/12/09 18:20:07 INFO spark.ExecutorAllocationManager: Requesting 2 new executors because tasks are backlogged (new desired total will be 2)
17/12/09 18:20:08 INFO spark.ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 3)
17/12/09 18:20:09 INFO spark.ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 4)
17/12/09 18:20:09 INFO cluster.YarnClientSchedulerBackend: Disabling executor 5.
17/12/09 18:20:09 INFO scheduler.DAGScheduler: Executor lost: 5 (epoch 5)
17/12/09 18:20:09 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 5 from BlockManagerMaster.
17/12/09 18:20:09 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(5, compute-1-2.local, 55142)
17/12/09 18:20:09 INFO storage.BlockManagerMaster: Removed 5 successfully in removeExecutor
17/12/09 18:20:09 ERROR cluster.YarnScheduler: Lost executor 5 on compute-1-2.local: Container marked as failed: container_e92_1512409949844_1822_01_000006 on host: compute-1-2.local. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal

17/12/09 18:20:09 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Container marked as failed: container_e92_1512409949844_1822_01_000006 on host: compute-1-2.local. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal

17/12/09 18:20:09 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 1.1 (TID 13, compute-1-2.local, executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container marked as failed: container_e92_1512409949844_1822_01_000006 on host: compute-1-2.local. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
Killed by external signal

17/12/09 18:20:10 INFO storage.BlockManagerMaster: Removal of executor 5 requested
17/12/09 18:20:10 INFO cluster.YarnClientSchedulerBackend: Asked to remove non-existent executor 5
17/12/09 18:20:10 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 5 from BlockManagerMaster.
17/12/09 18:20:10 INFO spark.ExecutorAllocationManager: Existing executor 5 has been removed (new total is 0)
17/12/09 18:20:10 INFO cluster.YarnClientSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (compute-1-4.local:50245) with ID 9
17/12/09 18:20:10 INFO spark.ExecutorAllocationManager: New executor 9 has registered (new total is 1)
17/12/09 18:20:10 INFO storage.BlockManagerMasterEndpoint: Registering block manager compute-1-4.local:44832 with 530.3 MB RAM, BlockManagerId(9, compute-1-4.local, 44832)
17/12/09 18:20:10 INFO scheduler.TaskSetManager: Starting task 0.1 in stage 1.1 (TID 14, compute-1-4.local, executor 9, partition 0, RACK_LOCAL, 1894 bytes)
17/12/09 18:20:10 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on compute-1-4.local:44832 (size: 32.1 KB, free: 530.2 MB)
17/12/09 18:20:10 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to compute-1-4.local:50245
17/12/09 18:20:11 INFO cluster.YarnClientSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (compute-1-13.local:42192) with ID 10
17/12/09 18:20:11 INFO spark.ExecutorAllocationManager: New executor 10 has registered (new total is 2)
17/12/09 18:20:11 INFO storage.BlockManagerMasterEndpoint: Registering block manager compute-1-13.local:36598 with 530.3 MB RAM, BlockManagerId(10, compute-1-13.local, 36598)
17/12/09 18:20:11 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 1.1 (TID 15, compute-1-13.local, executor 10, partition 1, RACK_LOCAL, 1894 bytes)
17/12/09 18:20:11 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on compute-1-13.local:36598 (size: 32.1 KB, free: 530.2 MB)
17/12/09 18:20:11 INFO cluster.YarnClientSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (compute-1-3.local:35744) with ID 11
17/12/09 18:20:11 INFO spark.ExecutorAllocationManager: New executor 11 has registered (new total is 3)
17/12/09 18:20:11 INFO storage.BlockManagerMasterEndpoint: Registering block manager compute-1-3.local:36924 with 530.3 MB RAM, BlockManagerId(11, compute-1-3.local, 36924)
17/12/09 18:20:11 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to compute-1-13.local:42192
17/12/09 18:20:11 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 1.1 (TID 16, compute-1-3.local, executor 11, partition 2, RACK_LOCAL, 1894 bytes)
17/12/09 18:20:12 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on compute-1-3.local:36924 (size: 32.1 KB, free: 530.2 MB)
17/12/09 18:20:12 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to compute-1-3.local:35744
17/12/09 18:20:16 INFO cluster.YarnClientSchedulerBackend: Disabling executor 10.
17/12/09 18:20:16 INFO scheduler.DAGScheduler: Executor lost: 10 (epoch 5)
17/12/09 18:20:16 ERROR client.TransportClient: Failed to send RPC 6818442344385493147 to compute-1-10.local/10.0.255.252:34705: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
17/12/09 18:20:16 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 10 from BlockManagerMaster.
17/12/09 18:20:16 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(10, compute-1-13.local, 36598)
17/12/09 18:20:16 INFO storage.BlockManagerMaster: Removed 10 successfully in removeExecutor
17/12/09 18:20:16 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Attempted to get executor loss reason for executor id 10 at RPC address compute-1-13.local:42192, but got no response. Marking as slave lost.
java.io.IOException: Failed to send RPC 6818442344385493147 to compute-1-10.local/10.0.255.252:34705: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$3.operationComplete(TransportClient.java:239)
	at org.apache.spark.network.client.TransportClient$3.operationComplete(TransportClient.java:226)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:680)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:567)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:424)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:801)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:699)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1122)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:633)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:32)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:908)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:960)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:893)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:357)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.nio.channels.ClosedChannelException
17/12/09 18:20:16 ERROR cluster.YarnScheduler: Lost executor 10 on compute-1-13.local: Slave lost
17/12/09 18:20:16 WARN scheduler.TaskSetManager: Lost task 1.0 in stage 1.1 (TID 15, compute-1-13.local, executor 10): ExecutorLostFailure (executor 10 exited caused by one of the running tasks) Reason: Slave lost
17/12/09 18:20:16 INFO spark.ExecutorAllocationManager: Existing executor 10 has been removed (new total is 2)
17/12/09 18:20:16 INFO cluster.YarnClientSchedulerBackend: Disabling executor 9.
17/12/09 18:20:16 INFO scheduler.DAGScheduler: Executor lost: 9 (epoch 5)
17/12/09 18:20:16 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 9 from BlockManagerMaster.
17/12/09 18:20:16 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(9, compute-1-4.local, 44832)
17/12/09 18:20:16 INFO storage.BlockManagerMaster: Removed 9 successfully in removeExecutor
17/12/09 18:20:16 ERROR client.TransportClient: Failed to send RPC 5173862225555890837 to compute-1-10.local/10.0.255.252:34705: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
17/12/09 18:20:16 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Attempted to get executor loss reason for executor id 9 at RPC address compute-1-4.local:50245, but got no response. Marking as slave lost.
java.io.IOException: Failed to send RPC 5173862225555890837 to compute-1-10.local/10.0.255.252:34705: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$3.operationComplete(TransportClient.java:239)
	at org.apache.spark.network.client.TransportClient$3.operationComplete(TransportClient.java:226)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:680)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:567)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:424)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:801)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:699)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1122)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:633)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:32)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:908)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:960)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:893)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:357)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.nio.channels.ClosedChannelException
17/12/09 18:20:16 ERROR cluster.YarnScheduler: Lost executor 9 on compute-1-4.local: Slave lost
17/12/09 18:20:16 WARN scheduler.TaskSetManager: Lost task 0.1 in stage 1.1 (TID 14, compute-1-4.local, executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Slave lost
17/12/09 18:20:16 INFO spark.ExecutorAllocationManager: Existing executor 9 has been removed (new total is 1)
17/12/09 18:20:17 INFO cluster.YarnClientSchedulerBackend: Disabling executor 11.
17/12/09 18:20:17 INFO scheduler.DAGScheduler: Executor lost: 11 (epoch 5)
17/12/09 18:20:17 ERROR client.TransportClient: Failed to send RPC 5540191721943683912 to compute-1-10.local/10.0.255.252:34705: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
17/12/09 18:20:17 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 11 from BlockManagerMaster.
17/12/09 18:20:17 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Attempted to get executor loss reason for executor id 11 at RPC address compute-1-3.local:35744, but got no response. Marking as slave lost.
java.io.IOException: Failed to send RPC 5540191721943683912 to compute-1-10.local/10.0.255.252:34705: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$3.operationComplete(TransportClient.java:239)
	at org.apache.spark.network.client.TransportClient$3.operationComplete(TransportClient.java:226)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:680)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:567)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:424)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:801)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:699)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1122)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:633)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:32)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:908)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:960)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:893)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:357)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.nio.channels.ClosedChannelException
17/12/09 18:20:17 ERROR cluster.YarnScheduler: Lost executor 11 on compute-1-3.local: Slave lost
17/12/09 18:20:17 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(11, compute-1-3.local, 36924)
17/12/09 18:20:17 INFO storage.BlockManagerMaster: Removed 11 successfully in removeExecutor
17/12/09 18:20:17 WARN scheduler.TaskSetManager: Lost task 2.0 in stage 1.1 (TID 16, compute-1-3.local, executor 11): ExecutorLostFailure (executor 11 exited caused by one of the running tasks) Reason: Slave lost
17/12/09 18:20:17 INFO spark.ExecutorAllocationManager: Existing executor 11 has been removed (new total is 0)
17/12/09 18:20:18 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(null)
17/12/09 18:20:18 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> babar.es.its.nyu.edu,compute-1-8.local, PROXY_URI_BASES -> http://babar.es.its.nyu.edu:8088/proxy/application_1512409949844_1822,http://compute-1-8.local:8088/proxy/application_1512409949844_1822), /proxy/application_1512409949844_1822
17/12/09 18:20:18 INFO ui.JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
17/12/09 18:25:48 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on 10.0.255.253:40982 in memory (size: 6.2 KB, free: 530.2 MB)
17/12/11 17:51:38 WARN hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  for block BP-1256044058-128.122.215.50-1440607644284:blk_1098145721_24471492
java.io.EOFException: Premature EOF: no length prefix available
	at org.apache.hadoop.hdfs.protocolPB.PBHelper.vintPrefixed(PBHelper.java:2272)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:235)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor.run(DFSOutputStream.java:1075)
17/12/11 17:51:38 WARN hdfs.DFSClient: Error Recovery for block BP-1256044058-128.122.215.50-1440607644284:blk_1098145721_24471492 in pipeline DatanodeInfoWithStorage[10.0.255.209:50010,DS-c5d26613-25b4-48b6-b0d7-a5a0e66b80c8,DISK], DatanodeInfoWithStorage[10.0.255.211:50010,DS-631f46f0-06d8-4c22-bd20-de767422a2ec,DISK], DatanodeInfoWithStorage[10.0.255.228:50010,DS-4421630f-1d24-498e-8238-2eaeb16b673e,DISK]: bad datanode DatanodeInfoWithStorage[10.0.255.209:50010,DS-c5d26613-25b4-48b6-b0d7-a5a0e66b80c8,DISK]
17/12/12 21:32:20 WARN hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  for block BP-1256044058-128.122.215.50-1440607644284:blk_1098145721_24567527
java.io.EOFException: Premature EOF: no length prefix available
	at org.apache.hadoop.hdfs.protocolPB.PBHelper.vintPrefixed(PBHelper.java:2272)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:235)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor.run(DFSOutputStream.java:1075)
17/12/12 21:32:20 WARN hdfs.DFSClient: Error Recovery for block BP-1256044058-128.122.215.50-1440607644284:blk_1098145721_24567527 in pipeline DatanodeInfoWithStorage[10.0.255.211:50010,DS-631f46f0-06d8-4c22-bd20-de767422a2ec,DISK], DatanodeInfoWithStorage[10.0.255.228:50010,DS-4421630f-1d24-498e-8238-2eaeb16b673e,DISK], DatanodeInfoWithStorage[10.0.255.250:50010,DS-2c889385-ebe3-43f5-8876-9be7f98325f0,DISK]: bad datanode DatanodeInfoWithStorage[10.0.255.211:50010,DS-631f46f0-06d8-4c22-bd20-de767422a2ec,DISK]
17/12/12 21:34:20 WARN hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  for block BP-1256044058-128.122.215.50-1440607644284:blk_1098145721_24665477
java.io.EOFException: Premature EOF: no length prefix available
	at org.apache.hadoop.hdfs.protocolPB.PBHelper.vintPrefixed(PBHelper.java:2272)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:235)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor.run(DFSOutputStream.java:1075)
17/12/12 21:47:52 INFO retry.RetryInvocationHandler: Exception while invoking getApplicationReport of class ApplicationClientProtocolPBClientImpl over rm86. Trying to fail over immediately.
java.io.IOException: Failed on local exception: java.io.IOException: Connection timed out; Host Details : local host is: "login-1-1.local/10.0.255.253"; destination host is: "babar.es.its.nyu.edu":8032; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1506)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230)
	at com.sun.proxy.$Proxy9.getApplicationReport(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationClientProtocolPBClientImpl.getApplicationReport(ApplicationClientProtocolPBClientImpl.java:187)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:256)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:104)
	at com.sun.proxy.$Proxy10.getApplicationReport(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.getApplicationReport(YarnClientImpl.java:408)
	at org.apache.spark.deploy.yarn.Client.getApplicationReport(Client.scala:265)
	at org.apache.spark.deploy.yarn.Client.monitorApplication(Client.scala:939)
	at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend$MonitorThread.run(YarnClientSchedulerBackend.scala:144)
Caused by: java.io.IOException: Connection timed out
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:553)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:254)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1111)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1006)
17/12/12 21:47:46 INFO retry.RetryInvocationHandler: Exception while invoking renewLease of class ClientNamenodeProtocolTranslatorPB over babar.es.its.nyu.edu/128.122.215.50:8020. Trying to fail over immediately.
org.apache.hadoop.net.ConnectTimeoutException: Call From login-1-1.local/10.0.255.253 to babar.es.its.nyu.edu:8020 failed on socket timeout exception: org.apache.hadoop.net.ConnectTimeoutException: 20000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=babar.es.its.nyu.edu/128.122.215.50:8020]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:750)
	at org.apache.hadoop.ipc.Client.call(Client.java:1506)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:590)
	at sun.reflect.GeneratedMethodAccessor17.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:256)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:104)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:942)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:423)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:448)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:304)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.net.ConnectTimeoutException: 20000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=babar.es.its.nyu.edu/128.122.215.50:8020]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:533)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:648)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:744)
	at org.apache.hadoop.ipc.Client$Connection.access$3000(Client.java:396)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1555)
	at org.apache.hadoop.ipc.Client.call(Client.java:1478)
	... 16 more
17/12/12 22:04:55 WARN hdfs.DFSClient: Error Recovery for block BP-1256044058-128.122.215.50-1440607644284:blk_1098145721_24665477 in pipeline DatanodeInfoWithStorage[10.0.255.228:50010,DS-4421630f-1d24-498e-8238-2eaeb16b673e,DISK], DatanodeInfoWithStorage[10.0.255.210:50010,DS-fe362d9c-2091-4a7a-81a1-a41ce0f6806e,DISK], DatanodeInfoWithStorage[10.0.255.250:50010,DS-2c889385-ebe3-43f5-8876-9be7f98325f0,DISK]: bad datanode DatanodeInfoWithStorage[10.0.255.228:50010,DS-4421630f-1d24-498e-8238-2eaeb16b673e,DISK]
17/12/12 22:04:55 INFO retry.RetryInvocationHandler: Exception while invoking renewLease of class ClientNamenodeProtocolTranslatorPB over master-1-1.local/10.0.255.251:8020 after 1 fail over attempts. Trying to fail over after sleeping for 1251ms.
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category WRITE is not supported in state standby. Visit https://s.apache.org/sbnn-error
	at org.apache.hadoop.hdfs.server.namenode.ha.StandbyState.checkOperation(StandbyState.java:88)
	at org.apache.hadoop.hdfs.server.namenode.NameNode$NameNodeHAContext.checkOperation(NameNode.java:1835)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkOperation(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewLease(FSNamesystem.java:5034)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.renewLease(NameNodeRpcServer.java:881)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.renewLease(AuthorizationProviderProxyClientProtocol.java:358)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.renewLease(ClientNamenodeProtocolServerSideTranslatorPB.java:648)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1073)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2220)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2216)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1920)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2214)

	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:590)
	at sun.reflect.GeneratedMethodAccessor17.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:256)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:104)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:942)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:423)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:448)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:304)
	at java.lang.Thread.run(Thread.java:745)
17/12/12 22:04:55 INFO retry.RetryInvocationHandler: Exception while invoking getAdditionalDatanode of class ClientNamenodeProtocolTranslatorPB over master-1-1.local/10.0.255.251:8020. Trying to fail over immediately.
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category READ is not supported in state standby. Visit https://s.apache.org/sbnn-error
	at org.apache.hadoop.hdfs.server.namenode.ha.StandbyState.checkOperation(StandbyState.java:88)
	at org.apache.hadoop.hdfs.server.namenode.NameNode$NameNodeHAContext.checkOperation(NameNode.java:1835)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkOperation(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalDatanode(FSNamesystem.java:3561)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getAdditionalDatanode(NameNodeRpcServer.java:717)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.getAdditionalDatanode(AuthorizationProviderProxyClientProtocol.java:230)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getAdditionalDatanode(ClientNamenodeProtocolServerSideTranslatorPB.java:519)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1073)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2220)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2216)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1920)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2214)

	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230)
	at com.sun.proxy.$Proxy15.getAdditionalDatanode(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getAdditionalDatanode(ClientNamenodeProtocolTranslatorPB.java:438)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:256)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:104)
	at com.sun.proxy.$Proxy16.getAdditionalDatanode(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.addDatanode2ExistingPipeline(DFSOutputStream.java:1346)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1512)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:1236)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:721)
17/12/12 22:04:55 INFO client.ConfiguredRMFailoverProxyProvider: Failing over to rm795
17/12/12 22:04:55 INFO retry.RetryInvocationHandler: Exception while invoking getApplicationReport of class ApplicationClientProtocolPBClientImpl over rm795 after 1 fail over attempts. Trying to fail over after sleeping for 110ms.
java.net.ConnectException: Call From login-1-1.local/10.0.255.253 to compute-1-8.local:8032 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:731)
	at org.apache.hadoop.ipc.Client.call(Client.java:1506)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230)
	at com.sun.proxy.$Proxy9.getApplicationReport(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationClientProtocolPBClientImpl.getApplicationReport(ApplicationClientProtocolPBClientImpl.java:187)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:256)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:104)
	at com.sun.proxy.$Proxy10.getApplicationReport(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.getApplicationReport(YarnClientImpl.java:408)
	at org.apache.spark.deploy.yarn.Client.getApplicationReport(Client.scala:265)
	at org.apache.spark.deploy.yarn.Client.monitorApplication(Client.scala:939)
	at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend$MonitorThread.run(YarnClientSchedulerBackend.scala:144)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:648)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:744)
	at org.apache.hadoop.ipc.Client$Connection.access$3000(Client.java:396)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1555)
	at org.apache.hadoop.ipc.Client.call(Client.java:1478)
	... 14 more
17/12/12 22:04:55 INFO client.ConfiguredRMFailoverProxyProvider: Failing over to rm86
17/12/12 22:04:57 WARN retry.RetryInvocationHandler: A failover has occurred since the start of this method invocation attempt.
